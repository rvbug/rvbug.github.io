{
  "hash": "4f4af4a6a8dc9f636b2406c15131490a",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Introduction to PTX\"\nauthor: \"Rakesh Venkat\"\ndate: \"2025-03-01\"\ncategories: [LLM]\nimage: \"img/ptx.png\"\njupyter: python3\n---\n\n# Introduction\n\nParallel Thread Execution (PTX) is a virtual machine instruction set architecture and can be thought of as the assembly language for NVDIA GPUs. You would need to know few syntax of PTX. This should get you started quickly.\n\n<!-- truncate -->\n\n------------------------------------------------------------------------\n\n# PTX Syntax\n\nHere are few syntax of PTX for your references.\n\n## **Basic Structure**\n\n``` ptx\n.version 7.0                    // PTX version\n.target sm_70                   // Target architecture\n.address_size 64                // 64-bit addressing\n\n.visible .entry kernel_name(   // Kernel name and declaration\n    .param .u64 param1,        // Parameters\n    .param .f32 param2\n)\n{\n    // Kernel body\n}\n```\n\n## **Registers**\n\n``` ptx\n.reg .b32 %r<5>;    // 5 32-bit registers %r0 through %r4\n.reg .f32 %f<3>;    // 3 single-precision float\n.reg .b64 %rd<2>;   // 2 64-bit \n.reg .pred %p<2>;   // 2 predicate registers (used for conditionals)\n```\n\n## **Instructions**\n\n``` ptx\nmov.u32 %r1, %tid.x;       // Move thread(ID) to %r1\nadd.s32 %r3, %r1, %r2;     // Add int\nmul.f32 %f3, %f1, %f2;     // Mul floats\nsetp.lt.s32 %p1, %r1, %r2; // Set predicate if r1 < r2\n@%p1 bra label;            // Conditional branch\n```\n\n## **Memory Operations**\n\n``` ptx\nld.param.u64 %rd1, [param1];       // Load param into register\nld.global.f32 %f1, [%rd1];         // Load from global mem\nst.global.f32 [%rd2], %f2;         // Store to global mem\nld.shared.f32 %f3, [%rd3];         // Load from shared mem\nld.global.v4.f16 {%f1, %f2, %f3, %f4}, [%rd1];  // Vector load\n```\n\n## **Special Registers**\n\n``` ptx\n%tid.x, %tid.y, %tid.z     // Thread (ID) within a block\n%ctaid.x, %ctaid.y, %ctaid.z   // Block (ID) within a grid\n%ntid.x, %ntid.y, %ntid.z  // Block dimensions (threads per block)\n```\n\n## **Math Operaations**\n\n``` ptx\nadd.f32 %f3, %f1, %f2;     // Add\nsub.f32 %f3, %f1, %f2;     // Sub\nmul.f32 %f3, %f1, %f2;     // Mul\ndiv.f32 %f3, %f1, %f2;     // Div\nmad.f32 %f4, %f1, %f2, %f3;  // Multiply & add: (f4 = f1*f2+f3)\n```\n\n## **Tensor Core Operations**\n\n``` ptx\n// Matrix multiply-accumulate using tensor cores\nmma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 \n    {%f5, %f6, %f7, %f8},   // Destination registers\n    {%f1, %f2},             // A matrix registers\n    {%f3, %f4},             // B matrix registers\n    {%f5, %f6, %f7, %f8};   // C matrix registers (accumulator)\n```\n\n## **Control Flow**\n\n``` ptx\nbra label;           // Unconditional branch\n@%p1 bra label;      // Conditional branch if predicate = true\nret;                 // Return from kernel\n```\n\n## Code Sample\n\nNow that we know the the basic syntax of PTX, here is one simple C program for vector addition.\n\n``` c\n\n#include <stdio.h>\n#include <cuda.h>\n#include <cuda_runtime.h>\n\n// Kernel function to add the elements of two arrays\n__global__ void vectorAdd(int *a, int *b, int *c, int n) {\n    int i = blockIdx.x * blockDim.x + threadIdx.x;\n    if (i < n) {\n        c[i] = a[i] + b[i];\n    }\n}\n\nint main() {\n    int n = 1000;\n    int size = n * sizeof(int);\n    int *a, *b, *c;\n    int *d_a, *d_b, *d_c;\n\n    // Allocate memory on the host\n    a = (int *)malloc(size);\n    b = (int *)malloc(size);\n    c = (int *)malloc(size);\n\n    // Initialize the arrays\n    for (int i = 0; i < n; i++) {\n        a[i] = i;\n        b[i] = i * 2;\n    }\n\n    // Allocate memory on the device\n    cudaMalloc((void **)&d_a, size);\n    cudaMalloc((void **)&d_b, size);\n    cudaMalloc((void **)&d_c, size);\n\n    // Copy data from host to device\n    cudaMemcpy(d_a, a, size, cudaMemcpyHostToDevice);\n    cudaMemcpy(d_b, b, size, cudaMemcpyHostToDevice);\n\n    // Launch the vectorAdd kernel\n    int threadsPerBlock = 256;\n    int blocksPerGrid = (n + threadsPerBlock - 1) / threadsPerBlock;\n    vectorAdd<<<blocksPerGrid, threadsPerBlock>>>(d_a, d_b, d_c, n);\n\n    // Copy the result from device to host\n    cudaMemcpy(c, d_c, size, cudaMemcpyDeviceToHost);\n\n    // Free device memory\n    cudaFree(d_a);\n    cudaFree(d_b);\n    cudaFree(d_c);\n\n    // Free host memory\n    free(a);\n    free(b);\n    free(c);\n\n    return 0;\n}\n```\n\n### Generating output\n\nLet us compile the code using `nvcc` compiler\n\n``` bash\n$> nvcc vector.cu -o vector\n$> ./my_kernel\n```\n\n``` bash\n# output\nc[0] = 0\nc[1] = 3\nc[2] = 6\nc[3] = 9\nc[4] = 12\nc[5] = 15\nc[6] = 18\nc[7] = 21\nc[8] = 24\nc[9] = 27\n```\n\n### Code Explaination\n\n``` c\n// This is for CUDA runtime functions\n#include <cuda_runtime.h> \n```\n\n#### Kernel Function\n\n-   *`__global__`* specifices that this is CUDA kernel that runs on GPU\\\n-   Three float arrays are pointers along with array size `a`, `b` and `c`\n-   *`blockIdx.x`* is the block index.\n-   *`blockDim.x`* is number of thread per block\n-   *`threadIdx.x`* is thread index within a block\n-   Calculate unique ID for each thread to process a different array element\n\n``` c\n// CUDA kernel for vector addition\n__global__ void vectorAdd(float *a, float *b, float *c, int n)\n{\n    // Calculate global thread ID\n    int id = blockIdx.x * blockDim.x + threadIdx.x;\n\n    // To make sure we don't go out of bounds\n    if (id < n)\n        c[id] = a[id] + b[id];\n}\n```\n\n#### Main function\n\n``` c\nint main()\n{\n    // Vector size\n    int n = 1000000;               // One million elements\n    size_t bytes = n * sizeof(float);  // Calculate memory size in bytes\n    // Allocate host memory\n    float *h_a = (float*)malloc(bytes);  // Allocate memory for array a\n    float *h_b = (float*)malloc(bytes);  // Allocate memory for array b\n    float *h_c = (float*)malloc(bytes);  // Allocate memory for results\n    // Initialize vectors on host\n    for (int i = 0; i < n; i++)\n    {\n        h_a[i] = 1.0f;  // All elements in a are 1.0\n        h_b[i] = 2.0f;  // All elements in b are 2.0\n    }\n}\n```\n\n#### GPU Memory Allocation\n\n``` c\n// Allocate device memory\n    float *d_a, *d_b, *d_c;            // Declare device pointers\n    cudaMalloc(&d_a, bytes);           // Allocate memory on GPU for a\n    cudaMalloc(&d_b, bytes);           // Allocate memory on GPU for b\n    cudaMalloc(&d_c, bytes);           // Allocate memory on GPU for c\n```\n\n#### GPU Data Transfer\n\n``` c\n// Copy data from host to device\n    cudaMemcpy(d_a, h_a, bytes, cudaMemcpyHostToDevice);  // Copy a to GPU\n    cudaMemcpy(d_b, h_b, bytes, cudaMemcpyHostToDevice);  // Copy b to GPU\n```\n\n#### Kernel Launch Configuration\n\n``` c\n// Set up execution configuration\n    int blockSize = 256;                         // 256 threads per block\n    int gridSize = (n + blockSize - 1) / blockSize;  // Calculate grid size\n// This formula ensures we have enough blocks to cover all elements\n// Launch kernel\n    vectorAdd<<<gridSize, blockSize>>>(d_a, d_b, d_c, n);\n    // <<<>>> is special CUDA syntax for kernel launch configuration\n    // gridSize = number of blocks, blockSize = threads per block\n```\n\n#### Results and Cleanup\n\n``` c\n// Copy result back to host\ncudaMemcpy(h_c, d_c, bytes, cudaMemcpyDeviceToHost);  // Copy results from GPU to CPU\n\n// Free memory\ncudaFree(d_a);  // Free GPU memory for a\ncudaFree(d_b);  // Free GPU memory for b\ncudaFree(d_c);  // Free GPU memory for c\nfree(h_a);      // Free CPU memory for a\nfree(h_b);      // Free CPU memory for b\nfree(h_c);      // Free CPU memory for c\n```\n\n## PTX Code\n\nTo extract PTX from the above code, try this the following command.\n\n``` bash\n$> nvcc -ptx vector.cu -o vector.ptx\n```\n\n### PTX file\n\n``` ptx\n\n.visible .entry vectorAdd(\n    .param .u64 vectorAdd_param_0,  // Pointer to array a\n    .param .u64 vectorAdd_param_1,  // Pointer to array b\n    .param .u64 vectorAdd_param_2,  // Pointer to array c\n    .param .u32 vectorAdd_param_3   // Parameter n (size)\n)\n{\n    .reg .pred  %p<2>;          // Predicate registers\n    .reg .f32   %f<4>;          // Float registers\n    .reg .b32   %r<6>;          // 32-bit registers\n    .reg .b64   %rd<11>;        // 64-bit registers\n\n    // Load parameters into registers\n    ld.param.u64    %rd1, [vectorAdd_param_0];\n    ld.param.u64    %rd2, [vectorAdd_param_1];\n    ld.param.u64    %rd3, [vectorAdd_param_2];\n    ld.param.u32    %r2, [vectorAdd_param_3];\n    \n    // Calculate thread ID\n    mov.u32         %r3, %ctaid.x;    // Get block index\n    mov.u32         %r4, %ntid.x;     // Get block size\n    mov.u32         %r5, %tid.x;      // Get thread index within block\n    mad.lo.s32      %r1, %r3, %r4, %r5;  // Calculate global thread ID: blockIdx * blockDim + threadIdx\n    \n    // Check if thread ID is within bounds\n    setp.ge.s32     %p1, %r1, %r2;    // Set predicate if thread ID >= n\n    @%p1 bra        BB0_2;            // If true, jump to the end (BB0_2 label)\n    \n    // Calculate memory addresses\n    cvta.to.global.u64  %rd4, %rd1;   // Convert array a pointer to global address\n    mul.wide.s32    %rd5, %r1, 4;     // Multiply thread ID by 4 (size of float)\n    add.s64         %rd6, %rd4, %rd5; // Calculate address for a[id]\n    \n    cvta.to.global.u64  %rd7, %rd2;   // Convert array b pointer to global address\n    add.s64         %rd8, %rd7, %rd5; // Calculate address for b[id]\n    \n    // Load values, add them, and store result\n    ld.global.f32   %f1, [%rd6];      // Load a[id]\n    ld.global.f32   %f2, [%rd8];      // Load b[id]\n    add.f32         %f3, %f1, %f2;    // Add them: c[id] = a[id] + b[id]\n    \n    cvta.to.global.u64  %rd9, %rd3;   // Convert array c pointer to global address\n    add.s64         %rd10, %rd9, %rd5; // Calculate address for c[id]\n    st.global.f32   [%rd10], %f3;     // Store the result in c[id]\n    \nBB0_2:                                // End label\n    ret;                              // Return from kernel\n}\n```\n\n### PTX Code\n\nLet us now review the PTX code\n\n### Entry Point\n\nThis section declares entry point for the kernel followed by 4 paramaters which is a pointer to the variable a, b, c and size n.\n\n``` ptx\n\n.visible .entry vectorAdd(           // Declares entry point for kernel\n    .param .u64 vectorAdd_param_0,   // First parameter (pointer to array a)\n    .param .u64 vectorAdd_param_1,   // Second parameter (pointer to array b)\n    .param .u64 vectorAdd_param_2,   // Third parameter (pointer to array c)\n    .param .u32 vectorAdd_param_3    // Fourth parameter (size n)\n)\n```\n\n### Register Declaration\n\nDeclating Predicate registers for conditions, float registers, 32 bit int and register for addresses\n\n``` ptx\n    .reg .pred  %p<2>;          // Predicate r\n    .reg .f32   %f<4>;          // Float \n    .reg .b32   %r<6>;          // 32-bit int\n    .reg .b64   %rd<11>;        // 64-bit for addresses\n```\n\n### Parameter Loading\n\nThis section loads parameters from kernel into registers. `ld` is for load.\n\n``` ptx\n\n    ld.param.u64    %rd1, [vectorAdd_param_0];  // Load pointer to array a\n    ld.param.u64    %rd2, [vectorAdd_param_1];  // Load pointer to array b\n    ld.param.u64    %rd3, [vectorAdd_param_2];  // Load pointer to array c\n    ld.param.u32    %r2, [vectorAdd_param_3];   // Load size n\n```\n\n### Thread ID\n\nNow calcuate unique thread Id using built-on registers.\n\nFirst get the current block index into `%r3`, then get number of threads per block into `%r4` and then get thread index within this block into `%r5`. `mad` is multiply and add in a single instruction and calculate ID by using `blockIdx * blockDim + threadIdx`.\n\n``` ptx\n    mov.u32         %r3, %ctaid.x;    \n    mov.u32         %r4, %ntid.x;     \n    mov.u32         %r5, %tid.x;      \n    mad.lo.s32      %r1, %r3, %r4, %r5; \n```\n\n### Bounds Checking\n\nHere we check if thread ID is within bounds of the array and then Set predicate `%p1` if thread ID \\>= n. If true then jump to return label `BB0_2`\n\n``` ptx\n// \nsetp.ge.s32     %p1, %r1, %r2;    // \n@%p1 bra        BB0_2;            // If true, jump to the return label (BB0_2)\n```\n\n### Memory Calculations\n\nCalculate memory address for array elements. Covert array `a` pointer to global address using `cvta`. Multiply `mul` thread Id by 4 which is the size of the float followed by adding address for `a`.\n\n``` ptx\n\n    cvta.to.global.u64  %rd4, %rd1;   \n    mul.wide.s32    %rd5, %r1, 4;     \n    add.s64         %rd6, %rd4, %rd5; \n    \n    cvta.to.global.u64  %rd7, %rd2;   // Convert array b pointer to global address\n    add.s64         %rd8, %rd7, %rd5; // Calculate address for b[id]\n```\n\n### Load, Add and Store\n\nLoad values from arrays, perform addition, and store result\n\n``` ptx\n    ld.global.f32   %f1, [%rd6];      // Load a[id] into register %f1\n    ld.global.f32   %f2, [%rd8];      // Load b[id] into register %f2\n    add.f32         %f3, %f1, %f2;    // Add them: %f3 = %f1 + %f2\n    \n    cvta.to.global.u64  %rd9, %rd3;   // Convert array c pointer to global address\n    add.s64         %rd10, %rd9, %rd5; // Calculate address for c[id]\n    st.global.f32   [%rd10], %f3;     // Store the result in c[id]\n```\n\n### Return from Kernel\n\n``` ptx\nBB0_2:  // Label for our return point\nret;                             \n```\n\n## Conclusion\n\nThis article covered the basic syntax of PTX. The next article will focus on how Deepseek could have possibly optimized their PTX code on their H800 NVIDIA GPUs.\n\n",
    "supporting": [
      "PTXIntro_files"
    ],
    "filters": [],
    "includes": {}
  }
}