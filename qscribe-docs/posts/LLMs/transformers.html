<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.31">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Rakesh Venkat">
<meta name="dcterms.date" content="2025-03-01">

<title>Transformers – QuBiTAi</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../images/AudioWide-White.ico" rel="icon">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-e1a5c8363afafaef2c763b6775fbf3ca.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-c1fac2584b48ed01fb6e278e36375074.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed fullcontent quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">QuBiTAi</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://qubitai.in/about.html" target="_blank"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/rvbug" target="_blank"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://qfey.in/" target="_blank"> 
<span class="menu-text">QFey</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://qubitai.in/" target="_blank"> 
<span class="menu-text">QuBiTAi</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Transformers</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">LLM</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Rakesh Venkat </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">March 1, 2025</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>In my previous blog post, I introduced Deepseek LLM’s innovative parallel thread execution (PTX) mechanism and how they use it for GPU optimization. Today, we’ll cover another foundational topic - <strong>Multihead Attention (MHA)</strong> before diving into Deepseek’s second groundbreaking innovation known as <strong>Multihead Latent Attention (MHLA)</strong>.</p>
<!-- truncate -->
<section id="multihead-latent-attention-roadmap" class="level2">
<h2 class="anchored" data-anchor-id="multihead-latent-attention-roadmap">Multihead Latent Attention Roadmap</h2>
<p>Logical progression to understand MHLA is as shown in the image below.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/MHLA roadmap.png" class="img-fluid figure-img"></p>
<figcaption>MHLA</figcaption>
</figure>
</div>
<p>The attention mechanism was introduced to solve fundamental limitations in the <strong><code>Encoder-Decoder</code></strong> architecture. Let’s examine why this was necessary.</p>
</section>
<section id="encoder-decoder" class="level2">
<h2 class="anchored" data-anchor-id="encoder-decoder">Encoder-Decoder</h2>
<p>Before attention mechanisms, sequence processing relied on RNN (<strong><code>Recurrent Neural Network</code></strong>) and LSTM (<strong><code>Long Short Term Memory</code></strong>) networks which had significant limitations:</p>
<ul>
<li>The encoder processes input token through LSTM/RNN cells, with the final hidden state (h3) passed to the decoder</li>
<li>All information from previous hidden states (h0, h1, h2) is compressed into a single vector called the context vector</li>
<li>This means that to generate outputs, the decoder only has access to this final hidden state</li>
<li>As a result, contextual information is lost when processing longer sequences</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/Encoder-decoder.png" class="img-fluid figure-img"></p>
<figcaption>Encoder-Decoder</figcaption>
</figure>
</div>
</section>
<section id="drawback-of-encoder-decoder" class="level2">
<h2 class="anchored" data-anchor-id="drawback-of-encoder-decoder">Drawback of Encoder-Decoder</h2>
<p>The traditional encoder-decoder suffered from several key limitations:</p>
<p><strong><code>Information Bottleneck</code></strong>: The entire input sequence had to be compressed into a single fixed-length context vector, regardless of the input sequence length.<br>
<strong><code>Long Range Dependencies</code></strong>: As sequence length increased, the model struggled to maintain relationships between positions.<br>
<strong><code>Vanishing Information</code></strong>: Information from the beginning of long sequences would “fade” by the time it reached the decoder.</p>
<p>These limitations were particularly problematic for machine translation tasks where sentences in different languages often have different structures and word orders.</p>
</section>
<section id="attention" class="level2">
<h2 class="anchored" data-anchor-id="attention">Attention</h2>
<p>The concept of <strong><code>Attention</code></strong> was introduced to solve the above challenges in a landmark paper <strong><code>Neural Machine Translation by Jointly Learning to Align and Translate</code></strong> by Bahdanau, Cho, and Bengio in 2014. It revolutionized the field of sequence processing by allowing neural networks to focus on specific parts of the input when generating outputs. You can find the paper <a href="https://arxiv.org/pdf/1409.0473"><strong>here</strong></a></p>
<div class="info">
<p>Decoder (s1) has now access to every hidden state and also the context of every hidden state in the encoder stage.</p>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/Encoder-decoder-attention.png" class="img-fluid figure-img"></p>
<figcaption>Encoder-Decoder-Attention</figcaption>
</figure>
</div>
<p>Another way of imagining the Attention Mechanism is as below. The attention block in between has the context information of inputs and much more richer containing semantic meaning.</p>
<div class="info">
<p>See the attention weights giving the importance for each hidden state in the below image</p>
<p>Key Improvement: The decoder (s1) now has access to every hidden state from the encoder stage, giving it context from the entire input sequence. The stronger colored bands in this visualization represent higher attention weights, showing which input tokens the model is focusing on when generating each output.</p>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/Attention.png" class="img-fluid figure-img"></p>
<figcaption>Attention</figcaption>
</figure>
</div>
<p>The Bahdanau attention mechanism allowed decoder to “look back” at the entire sequence of encoder hidden states when generating each output token. Rather than relying solely on a fixed context vector, the decoder could dynamically focus on relevant parts of the input sequence.</p>
</section>
<section id="self-attention" class="level2">
<h2 class="anchored" data-anchor-id="self-attention">Self Attention</h2>
<p>To understand how everything fits together, let’s revisit the transformer architecture:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/LLMarch.png" class="img-fluid figure-img"></p>
<figcaption>LLM Architecture</figcaption>
</figure>
</div>
<p>As a block schematic, self-attention will look something like this:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/SelfAttention-Calc.png" class="img-fluid figure-img"></p>
<figcaption>SelfAttention</figcaption>
</figure>
</div>
<p>Where:</p>
<p>$ X : $ <code>Input embedding (Token Embedding + Positional Encoding)</code><br>
$ W_Q : $ <code>Trainable Query Matrix</code><br>
$ W_K : $ <code>Trainable Key Matrix</code><br>
$ W_V : $ <code>Trainable Value Matrix</code><br>
$ (d_k): $ <code>Square Root of keys dimensions</code></p>
<div class="tip">
<p>Example: See how the word “Data” interacts with surrounding words. Each word calculates attention scores with every other word in the sequence:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/Self-attention-eg.png" class="img-fluid figure-img"></p>
<figcaption>Self Attention</figcaption>
</figure>
</div>
</div>
<div class="info">
<p>The process works something like this:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/SelfAttention-KeysValue.png" class="img-fluid figure-img"></p>
<figcaption>Keysvalue</figcaption>
</figure>
</div>
<p><code>Attention Score will then be calculated as :</code><br>
$ x_2 x_1 $<br>
$ x_2 x_2 $<br>
$ x_2 x_3 $<br>
$ x_2 x_4 $</p>
<p><code>Attention Weights will be :</code></p>
<p>$ Attention Weight = $ softmax <span class="math inline">\(([\alpha_{21},\alpha_{22},\alpha_{23},\alpha_{24}])\)</span> = <span class="math inline">\(([w_{21},w_{22},w_{23},w_{24}])\)</span></p>
<p><code>Finally Context Vector for "Data" will then be :</code></p>
<p>$ Context Vector_{Data} = $ $ (w_{21} v_1) + $ $ (w_{22} v_2) + $ $ (w_{23} v_3) + $ $ (w_{24} v_4) $</p>
<p>Where: <span class="math inline">\(v_1 ,v_1, v_1, v_1\)</span> are Value Matrix</p>
</div>
</section>
<section id="self-attention---dimensions" class="level2">
<h2 class="anchored" data-anchor-id="self-attention---dimensions">Self Attention - Dimensions</h2>
<div class="tip">
<p>Note: Understanding tensors (multi-dimensional arrays) and matrix multiplication is essential here. With practice, these operations become intuitive.</p>
</div>
<p>Here’s how input text is processed through the self-attention blocks, including sample matrix dimensions:</p>
<div class="note">
<ul>
<li>The numbers in brackets represent dimensions (e.g., <span class="math inline">\(W_Q\)</span> has dimensions <span class="math inline">\([10, 5]\)</span>)</li>
<li>This example processes 6 words (i.e.&nbsp;6 tokens)</li>
<li>The context vector output feeds into the logits layer to calculate probabilities for the next word</li>
<li>While we show just one transformer block here, modern architectures stack multiple blocks</li>
</ul>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/attention-matrix.png" class="img-fluid figure-img"></p>
<figcaption>Attention-Matrix</figcaption>
</figure>
</div>
</section>
<section id="causal-attention" class="level2">
<h2 class="anchored" data-anchor-id="causal-attention">Causal Attention</h2>
<p>Causal attention which is also known as <code>Masked Attention</code> is a variant used in language models that ensures tokens can only attend to themselves and previous tokens in the sequence. This maintains the autoregressive property needed for text generation, where each token is predicted based only on previously observed tokens.</p>
<div class="info">
<p>Autoregression: The output for each word goes back as an input to predict the next word. <img src="img/AutoregressiveModel.png" class="img-fluid" alt="AutoRegression"></p>
</div>
<p>Let’s take a simpler example: in the sentence <code>THE DATA IS HUGE</code>, when predicting the word <code>IS</code>, causal attention only needs to calculate attention scores for <code>THE</code> and <code>DATA</code> (previous and current tokens). This significantly reduces computation compared to full self attention, which would unnecessarily calculate scores for future tokens like <code>HUGE</code>.</p>
</section>
<section id="efficiency-advantage" class="level2">
<h2 class="anchored" data-anchor-id="efficiency-advantage">Efficiency Advantage</h2>
<p>One significant benefit of causal attention is computational efficiency. Since each token only needs to calculate attention weights for itself and preceding tokens but not future tokens, the number of calculations decreases substantially:</p>
<ul>
<li>For the first token: only 1 attention weight calculation</li>
<li>For the second token: 2 attention weight calculations</li>
<li>For the third token: 3 attention weight calculations</li>
<li>And so on…</li>
</ul>
<p>In causal attention, we apply a mask to the attention scores matrix that sets all future position scores to negative infinity before the softmax operation</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/CausalAttention.png" class="img-fluid figure-img"></p>
<figcaption>CausalAttention</figcaption>
</figure>
</div>
</section>
<section id="multihead-attention" class="level2">
<h2 class="anchored" data-anchor-id="multihead-attention">Multihead Attention</h2>
<p>But why would you need Multihead attention? Have a look at this sentence - <code>The programmer compiled the code, but it still had bugs in it</code>.</p>
<p>In this sentence, we have two instances of “it”. First “it” refers to “complation of the code” and second “it” refers “bug in the code”. If we get the token ids then it will look something like this.</p>
<p>Both instances of ‘it’ have identical token IDs, but they refer to different concepts in the sentence. This shows why we need multiple perspectives of the input sequence, as a single attention mechanism might not capture these different contextual meanings.</p>
<p>[10] [23] [3] [34] [50] [89] [14] <strong><code>[77]</code></strong> [69] [8] [15] [9] <strong><code>[77]</code></strong> [.]</p>
<p>That means the context is completly lost since it will have only one perspective. What if we somehow capture different perspective of a given input sequence?</p>
<p>Instead of performing a single attention operation, multihead attention performs multiple attention in parallel. Each “head” learns different relationship or patterns or perspective:</p>
</section>
<section id="method" class="level2">
<h2 class="anchored" data-anchor-id="method">Method</h2>
<p>Take a look at this image. Here the input dimension is split into two heads which captures two perspective of a sentence.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/Multihead-atten.png" class="img-fluid figure-img"></p>
<figcaption>MultiHead</figcaption>
</figure>
</div>
<ul>
<li>Split the embedding dimension into multiple heads</li>
<li>Each head performs its own Query, Key, Value projections</li>
<li>Calculate attention independently in each head</li>
<li>Concatenate results and project back to original dimension</li>
</ul>
<p>This allows the model to jointly attend to information from different representation subspaces, capturing different aspects of the input sequence.</p>
<p>Mathematically :-</p>
<p><span class="math inline">\(\text{MultiHead}(Q, K, V) = \text{Concat}(\text{head}_1, ..., \text{head}_h) \circ W^O\)</span></p>
<p>Where each head is:<br>
<span class="math inline">\(\text{head}_i = \text{Attention}(QW^Q_i, KW^K_i, VW^V_i)\)</span></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/selfAttenMatrix.png" class="img-fluid figure-img"></p>
<figcaption>Matrix</figcaption>
</figure>
</div>
</section>
<section id="code" class="level2">
<h2 class="anchored" data-anchor-id="code">Code</h2>
<p>Let us see some code we discussed so far.</p>
<p>Assume that the input $ x $ is the input embedding which is tokenized and positional encoding is applied</p>
<p>Output of $ x = $ [1, 3, 6] which is read as follows: <em><code>3 rows , 6 columns and batch size is 1</code></em>.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="co"># decode d_out and number of heads</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="co"># head_dimn = d_out/n_heads</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>d_out <span class="op">=</span> <span class="dv">6</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>num_heads <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>head_dimn <span class="op">=</span> <span class="bu">int</span>(d_out<span class="op">/</span>num_heads)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"output dimn is:"</span>, d_out)</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"number of heads is:"</span>, num_heads)</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"head dimn is:"</span>, head_dimn)</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor([[[<span class="fl">0.1</span>, <span class="fl">0.2</span>, <span class="fl">0.3</span>, <span class="fl">0.4</span>, <span class="fl">0.5</span>, <span class="fl">0.6</span>], </span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>                    [<span class="fl">0.7</span>, <span class="fl">0.8</span>, <span class="fl">0.9</span>, <span class="fl">0.10</span>, <span class="fl">0.11</span>, <span class="fl">0.12</span>], </span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>                    [<span class="fl">0.13</span>, <span class="fl">0.14</span>, <span class="fl">0.15</span>, <span class="fl">0.16</span>, <span class="fl">0.17</span>, <span class="fl">0.18</span>]]])</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>batch, tokenid, d_in <span class="op">=</span> x.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Trainable matrix $ W_q, W_k, W_v $</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>W_Query <span class="op">=</span> torch.nn.Linear(d_in, d_out, bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>W_Key <span class="op">=</span> torch.nn.Linear(d_in, d_out, bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>W_Value <span class="op">=</span> torch.nn.Linear(d_in, d_out, bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="co"># get the key , query and values matrix </span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>keys <span class="op">=</span> W_Key(x)</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>query <span class="op">=</span> W_Query(x)</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>values <span class="op">=</span> W_Value(x)</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a><span class="co"># 3 rows and 6 columns having 1 batch</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(query.shape)</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(keys.shape)</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(values.shape)</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a><span class="co"># convert [batch, tokens, d_out] to [batch, token, num_heads, head_dimn]</span></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a><span class="co"># 3 Dimensional [1,3,6] -&gt; 4 Dimensional [1,3,2,3] i.e. 1 batch of 2x3 having 3 such sets</span></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>keys <span class="op">=</span> keys.view(batch, tokenid, num_heads, head_dimn)</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>query <span class="op">=</span> query.view(batch, tokenid, num_heads, head_dimn)</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>values <span class="op">=</span> values.view(batch, tokenid, num_heads, head_dimn)</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(keys.shape, query.shape, values.shape)</span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>keys</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a>att_score <span class="op">=</span> query <span class="op">@</span> keys.transpose(<span class="dv">2</span>,<span class="dv">3</span>) <span class="co"># this results in Q1 x K1(transpose) &amp; Q2 x K2(transpose)</span></span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(att_score.shape)</span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a><span class="co"># this is attention score of head1 and head 2 with tokenid in columns and tokenids in rows i.e. tokenids x tokenids</span></span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a>att_score </span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a><span class="co"># To get attention weights we need to do the following</span></span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a><span class="co"># scaling by sqrt(key dimns) + softmax + causal attention + dropouts</span></span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a><span class="co"># first apply mask on the upper triangle of the matrix on tokenids which is 3x3</span></span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a>mask <span class="op">=</span> torch.triu(torch.ones(<span class="dv">3</span>,<span class="dv">3</span>), diagonal<span class="op">=</span><span class="dv">1</span>).<span class="bu">bool</span>()</span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a>mask</span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-40"><a href="#cb2-40" aria-hidden="true" tabindex="-1"></a><span class="co"># we need to now change the mask to -inf so when we apply softmax, it will be turn to zeros</span></span>
<span id="cb2-41"><a href="#cb2-41" aria-hidden="true" tabindex="-1"></a>att_score.masked_fill_( mask, <span class="bu">float</span>(<span class="st">'-inf'</span>))</span>
<span id="cb2-42"><a href="#cb2-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-43"><a href="#cb2-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-44"><a href="#cb2-44" aria-hidden="true" tabindex="-1"></a>sqrt_d <span class="op">=</span> keys.shape[<span class="op">-</span><span class="dv">1</span>]<span class="op">**</span><span class="fl">0.5</span></span>
<span id="cb2-45"><a href="#cb2-45" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"square root of keys is : "</span>, sqrt_d)</span>
<span id="cb2-46"><a href="#cb2-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-47"><a href="#cb2-47" aria-hidden="true" tabindex="-1"></a><span class="co"># apply softmax on the last dimension which is length of the tokenids [batch, num_heads, tokenids, tokenids]</span></span>
<span id="cb2-48"><a href="#cb2-48" aria-hidden="true" tabindex="-1"></a>attn_weights <span class="op">=</span> torch.softmax(att_score<span class="op">/</span>sqrt_d, dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb2-49"><a href="#cb2-49" aria-hidden="true" tabindex="-1"></a>attn_weights</span>
<span id="cb2-50"><a href="#cb2-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-51"><a href="#cb2-51" aria-hidden="true" tabindex="-1"></a><span class="co"># context vector is attn_weights * value matrix</span></span>
<span id="cb2-52"><a href="#cb2-52" aria-hidden="true" tabindex="-1"></a>values.shape, values</span>
<span id="cb2-53"><a href="#cb2-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-54"><a href="#cb2-54" aria-hidden="true" tabindex="-1"></a>context_vector <span class="op">=</span> (attn_weights <span class="op">@</span> values)</span>
<span id="cb2-55"><a href="#cb2-55" aria-hidden="true" tabindex="-1"></a>context_vector.shape, context_vector</span>
<span id="cb2-56"><a href="#cb2-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-57"><a href="#cb2-57" aria-hidden="true" tabindex="-1"></a><span class="co"># if you want projection (optional) </span></span>
<span id="cb2-58"><a href="#cb2-58" aria-hidden="true" tabindex="-1"></a>context_vec <span class="op">=</span> torch.nn.Module.out_proj </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>Now that we’ve established a solid understanding of conventional attention mechanisms, in the next post we’ll explore Deepseek’s innovative <strong><code>Multihead Latent Attention (MHLA)</code></strong>. This technique represents a significant advancement that improves both computational efficiency and model performance by operating in a more compact latent space. MHLA reduces computational complexity while maintaining or even enhancing the model’s ability to capture relationships between tokens, particularly for long sequences. Stay tuned to learn how this optimization technique can be applied to your own language models!</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/qubitai\.in\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>